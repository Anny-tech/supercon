{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c6a1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCross-tabs, Filters, and Quality Flags Analysis\\n================================================\\nAuthor: Ankita Biswas\\nProject: Public Dashboard for Superconductors\\nDate: December 2025\\n\\nThis script generates analyses 4 and 5 from the project proposal:\\n4. Cross-tabs and filters (element presence vs Tc bins, composition complexity)\\n5. Provenance & quality flags (data quality visualizations)\\n\\nThese outputs are specifically designed for dashboard integration.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cross-tabs, Filters, and Quality Flags Analysis\n",
    "================================================\n",
    "Author: Ankita Biswas\n",
    "Project: Public Dashboard for Superconductors\n",
    "Date: December 2025\n",
    "\n",
    "This script generates analyses 4 and 5 from the project proposal:\n",
    "4. Cross-tabs and filters (element presence vs Tc bins, composition complexity)\n",
    "5. Provenance & quality flags (data quality visualizations)\n",
    "\n",
    "These outputs are specifically designed for dashboard integration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c336fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digifort/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['savefig.dpi'] = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8bc35",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9070427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-TABS AND QUALITY FLAGS ANALYSIS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = '/home/digifort/Documents/Data_Management_F25/supercon/feature_engineered_data/superconductors_with_features.csv'\n",
    "OUTPUT_DIR = '/home/digifort/Documents/Data_Management_F25/supercon/analysis_results/'\n",
    "FIGURES_DIR = os.path.join(OUTPUT_DIR, 'figures/')\n",
    "TABLES_DIR = os.path.join(OUTPUT_DIR, 'tables/')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "os.makedirs(TABLES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ae0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-TABS AND QUALITY FLAGS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "Loaded 15,845 records\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS 4: CROSS-TABS AND FILTERS\n",
      "================================================================================\n",
      "\n",
      "[4.1] Element presence cross-tabulation...\n",
      "  Using top 15 elements: Cu, O, Ba, Sr, Ca, Y, La, Fe, Bi, As, Nb, Pb, C, Ni, Pr\n",
      "\n",
      "Creating cross-tabulation tables...\n",
      "Saved: element_tc_crosstab_counts.csv\n",
      "\n",
      " Element presence by Tc category (count of materials):\n",
      "                   Cu     O    Ba    Sr    Ca     Y   La   Fe   Bi   As   Nb  \\\n",
      "tc_category                                                                    \n",
      "Very Low (<10K)   487   789   331   331   165   396  832  437  545  296  683   \n",
      "Low (10-30K)     1473  1689   690   826   385   406  911  855  255  665  492   \n",
      "Medium (30-77K)  2745  2591  1698  1276  1153  1045  769  533  365  275    7   \n",
      "High (>77K)      2322  1926  1656   835  1249   909  192   66  534    1    1   \n",
      "\n",
      "                  Pb    C   Ni   Pr  \n",
      "tc_category                          \n",
      "Very Low (<10K)  335  511  550  190  \n",
      "Low (10-30K)     140  326  197  233  \n",
      "Medium (30-77K)  276   87   83  355  \n",
      "High (>77K)      320   43   53  103  \n",
      "Saved: element_tc_crosstab_percentages.csv\n",
      "Saved: 04a_element_tc_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CROSS-TABS AND QUALITY FLAGS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nLoading data...\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Parse elements column\n",
    "if 'elements' in df.columns and df['elements'].dtype == 'object':\n",
    "    df['elements'] = df['elements'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "print(f\"Loaded {len(df):,} records\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS 4: CROSS-TABS AND FILTERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "print(\"\\n[4.1] Element presence cross-tabulation...\")\n",
    "\n",
    "# Get top elements\n",
    "all_elements = []\n",
    "for elem_set in df['elements'].dropna():\n",
    "    if isinstance(elem_set, set):\n",
    "        all_elements.extend(elem_set)\n",
    "\n",
    "element_counts = Counter(all_elements)\n",
    "top_elements = [e[0] for e in element_counts.most_common(15)]  # Top 15 elements\n",
    "\n",
    "print(f\"  Using top 15 elements: {', '.join(top_elements)}\")\n",
    "\n",
    "# Create binary presence columns\n",
    "for elem in top_elements:\n",
    "    df[f'has_{elem}'] = df['elements'].apply(\n",
    "        lambda x: 1 if (isinstance(x, set) and elem in x) else 0\n",
    "    )\n",
    "\n",
    "# Create Tc bins\n",
    "tc_bins = [0, 10, 30, 77, df['tc_kelvin'].max() + 1]\n",
    "tc_labels = ['Very Low (<10K)', 'Low (10-30K)', 'Medium (30-77K)', 'High (>77K)']\n",
    "df['tc_category'] = pd.cut(df['tc_kelvin'], bins=tc_bins, labels=tc_labels)\n",
    "\n",
    "# Cross-tab: Tc category vs element presence\n",
    "print(\"\\nCreating cross-tabulation tables...\")\n",
    "\n",
    "# Method 1: Count of materials per Tc category with each element\n",
    "crosstab_count = pd.DataFrame()\n",
    "for elem in top_elements:\n",
    "    counts = df.groupby(['tc_category', f'has_{elem}']).size().unstack(fill_value=0)\n",
    "    if 1 in counts.columns:\n",
    "        crosstab_count[elem] = counts[1]  # Only materials that contain the element\n",
    "    else:\n",
    "        crosstab_count[elem] = 0\n",
    "\n",
    "crosstab_count.to_csv(os.path.join(TABLES_DIR, 'element_tc_crosstab_counts.csv'))\n",
    "print(\"Saved: element_tc_crosstab_counts.csv\")\n",
    "\n",
    "print(\"\\n Element presence by Tc category (count of materials):\")\n",
    "print(crosstab_count)\n",
    "\n",
    "# Method 2: Percentage of materials in each Tc category that contain each element\n",
    "crosstab_pct = pd.DataFrame()\n",
    "for category in tc_labels:\n",
    "    cat_df = df[df['tc_category'] == category]\n",
    "    if len(cat_df) > 0:\n",
    "        pcts = []\n",
    "        for elem in top_elements:\n",
    "            pct = 100 * cat_df[f'has_{elem}'].sum() / len(cat_df)\n",
    "            pcts.append(pct)\n",
    "        crosstab_pct[category] = pcts\n",
    "\n",
    "crosstab_pct.index = top_elements\n",
    "crosstab_pct.to_csv(os.path.join(TABLES_DIR, 'element_tc_crosstab_percentages.csv'))\n",
    "print(\"Saved: element_tc_crosstab_percentages.csv\")\n",
    "\n",
    "# Visualize cross-tab as heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(crosstab_pct, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': '% of Materials'}, ax=ax)\n",
    "ax.set_xlabel('Tc Category', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Element', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Element Prevalence by Tc Category (%)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '04a_element_tc_heatmap.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: 04a_element_tc_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc1624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4.2] Composition complexity analysis...\n",
      "  Tc statistics by number of elements:\n",
      "            count   mean  median    std    min     max\n",
      "n_elements                                            \n",
      "1              60   4.72    2.92   6.99   0.02   47.83\n",
      "2            2483   4.86    3.37  10.54   0.01  294.00\n",
      "3            3483   8.46    5.15   9.80   0.01  132.00\n",
      "4            2907  25.27   13.65  29.25   0.03  287.00\n",
      "5            3968  45.99   38.00  31.95   0.01  135.80\n",
      "6            1988  54.43   55.40  31.80   0.20  143.00\n",
      "7             751  67.93   71.30  29.54   0.40  133.00\n",
      "8             192  79.08   85.48  30.49   6.00  136.00\n",
      "9              13  82.48   79.80  26.38  45.30  123.50\n",
      "Saved: 04b_complexity_vs_tc.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4.2] Composition complexity analysis...\")\n",
    "\n",
    "# Number of elements vs Tc\n",
    "complexity_stats = df.groupby('n_elements')['tc_kelvin'].agg([\n",
    "    'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "]).round(2)\n",
    "complexity_stats = complexity_stats[complexity_stats['count'] >= 5]  # At least 5 samples\n",
    "complexity_stats.to_csv(os.path.join(TABLES_DIR, 'tc_by_complexity.csv'))\n",
    "\n",
    "print(\"  Tc statistics by number of elements:\")\n",
    "print(complexity_stats)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar plot: Mean Tc vs n_elements\n",
    "axes[0].bar(complexity_stats.index, complexity_stats['mean'], \n",
    "            yerr=complexity_stats['std'], capsize=5, \n",
    "            color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axhline(77, color='red', linestyle='--', alpha=0.5, label='LN₂ temp (77K)')\n",
    "axes[0].set_xlabel('Number of Elements', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Mean Tc (K)', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Tc vs Compositional Complexity', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Violin plot\n",
    "valid_n_elements = complexity_stats.index.tolist()\n",
    "data_to_plot = [df[df['n_elements'] == n]['tc_kelvin'].dropna() for n in valid_n_elements]\n",
    "\n",
    "parts = axes[1].violinplot(data_to_plot, positions=valid_n_elements, widths=0.7, \n",
    "                           showmeans=True, showmedians=True)\n",
    "axes[1].axhline(77, color='red', linestyle='--', alpha=0.5, label='LN₂ temp (77K)')\n",
    "axes[1].set_xlabel('Number of Elements', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Tc (K)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Tc Distribution by Complexity', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '04b_complexity_vs_tc.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: 04b_complexity_vs_tc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0ba51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4.3] Composition keyword analysis...\n",
      "  Composition keyword statistics:\n",
      "        combination  count   mean_tc  median_tc  max_tc  high_tc_fraction\n",
      "      Tl+Ba+Ca+Cu+O    124 99.031113     108.00   125.5          0.854839\n",
      "            Hg+Cu+O    237 90.149958      91.60   143.0          0.700422\n",
      "      Bi+Sr+Ca+Cu+O    616 79.873164      83.90   136.0          0.626623\n",
      "          Y+Ba+Cu+O   1609 66.090862      73.00   127.0          0.436917\n",
      "    Cu+O (Cuprates)   5916 56.543981      58.00   275.0          0.324882\n",
      "            La+Cu+O   1591 37.754881      30.50    99.0          0.106223\n",
      "   Mg+B (MgB2-type)    192 30.191968      34.00    41.4          0.000000\n",
      "Fe+As/P (Pnictides)   1150 21.867391      19.85   287.0          0.000870\n",
      "           Nb-based   1183 10.106912       8.87    77.3          0.000845\n",
      " Saved: 04c_keyword_combinations.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4.3] Composition keyword analysis...\")\n",
    "\n",
    "# Key element combinations for superconductors\n",
    "element_combinations = {\n",
    "    'Cu+O (Cuprates)': ['Cu', 'O'],\n",
    "    'Fe+As/P (Pnictides)': ['Fe', ['As', 'P']],\n",
    "    'Hg+Cu+O': ['Hg', 'Cu', 'O'],\n",
    "    'Nb-based': ['Nb'],\n",
    "    'Mg+B (MgB2-type)': ['Mg', 'B'],\n",
    "    'La+Cu+O': ['La', 'Cu', 'O'],\n",
    "    'Y+Ba+Cu+O': ['Y', 'Ba', 'Cu', 'O'],\n",
    "    'Bi+Sr+Ca+Cu+O': ['Bi', 'Sr', 'Ca', 'Cu', 'O'],\n",
    "    'Tl+Ba+Ca+Cu+O': ['Tl', 'Ba', 'Ca', 'Cu', 'O']\n",
    "}\n",
    "\n",
    "def has_element_combination(elements, combo):\n",
    "    \"\"\"Check if material contains required element combination\"\"\"\n",
    "    if not isinstance(elements, set):\n",
    "        return False\n",
    "    \n",
    "    for item in combo:\n",
    "        if isinstance(item, list):\n",
    "            # Any of the elements in the list\n",
    "            if not any(e in elements for e in item):\n",
    "                return False\n",
    "        else:\n",
    "            # Specific element required\n",
    "            if item not in elements:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "combo_stats = []\n",
    "for combo_name, combo_elements in element_combinations.items():\n",
    "    mask = df['elements'].apply(lambda x: has_element_combination(x, combo_elements))\n",
    "    subset = df[mask]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        combo_stats.append({\n",
    "            'combination': combo_name,\n",
    "            'count': len(subset),\n",
    "            'mean_tc': subset['tc_kelvin'].mean(),\n",
    "            'median_tc': subset['tc_kelvin'].median(),\n",
    "            'max_tc': subset['tc_kelvin'].max(),\n",
    "            'high_tc_fraction': (subset['tc_kelvin'] > 77).sum() / len(subset)\n",
    "        })\n",
    "\n",
    "combo_df = pd.DataFrame(combo_stats).sort_values('mean_tc', ascending=False)\n",
    "combo_df.to_csv(os.path.join(TABLES_DIR, 'keyword_combinations.csv'), index=False)\n",
    "\n",
    "print(\"  Composition keyword statistics:\")\n",
    "print(combo_df.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "x_pos = np.arange(len(combo_df))\n",
    "bars = ax.barh(x_pos, combo_df['mean_tc'], color='forestgreen', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Color by mean Tc\n",
    "colors = plt.cm.RdYlBu_r((combo_df['mean_tc'] - combo_df['mean_tc'].min()) / \n",
    "                         (combo_df['mean_tc'].max() - combo_df['mean_tc'].min()))\n",
    "for bar, color in zip(bars, colors):\n",
    "    bar.set_facecolor(color)\n",
    "\n",
    "ax.set_yticks(x_pos)\n",
    "ax.set_yticklabels(combo_df['combination'], fontsize=10)\n",
    "ax.set_xlabel('Mean Tc (K)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Mean Tc by Composition Keywords', fontsize=13, fontweight='bold')\n",
    "ax.axvline(77, color='red', linestyle='--', alpha=0.5, label='LN₂ temp (77K)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '04c_keyword_combinations.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\" Saved: 04c_keyword_combinations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f497186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4.4] Temporal trends analysis...\n",
      "Saved: 04d_temporal_trends.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4.4] Temporal trends analysis...\")\n",
    "\n",
    "if 'publication_year' in df.columns:\n",
    "    # Filter valid years\n",
    "    valid_years = df[(df['publication_year'] >= 1900) & (df['publication_year'] <= 2025)]\n",
    "    \n",
    "    year_stats = valid_years.groupby('publication_year').agg({\n",
    "        'tc_kelvin': ['count', 'mean', 'median', 'max'],\n",
    "        'is_high_tc': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    year_stats.columns = ['year', 'count', 'mean_tc', 'median_tc', 'max_tc', 'high_tc_count']\n",
    "    year_stats['high_tc_fraction'] = year_stats['high_tc_count'] / year_stats['count']\n",
    "    \n",
    "    # Only keep years with at least 5 discoveries\n",
    "    year_stats = year_stats[year_stats['count'] >= 5]\n",
    "    year_stats.to_csv(os.path.join(TABLES_DIR, 'temporal_trends.csv'), index=False)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Number of discoveries\n",
    "    axes[0].bar(year_stats['year'], year_stats['count'], \n",
    "                color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_ylabel('Number of Materials', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Superconductor Discoveries Over Time', fontsize=13, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Maximum Tc evolution\n",
    "    axes[1].plot(year_stats['year'], year_stats['max_tc'], \n",
    "                 'o-', linewidth=2, markersize=6, color='red', label='Max Tc')\n",
    "    axes[1].plot(year_stats['year'], year_stats['mean_tc'], \n",
    "                 's-', linewidth=2, markersize=5, color='blue', alpha=0.7, label='Mean Tc')\n",
    "    axes[1].axhline(77, color='green', linestyle='--', alpha=0.5, label='LN₂ temp (77K)')\n",
    "    axes[1].set_ylabel('Tc (K)', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Evolution of Tc Records', fontsize=13, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # High-Tc fraction\n",
    "    axes[2].fill_between(year_stats['year'], year_stats['high_tc_fraction'] * 100, \n",
    "                         alpha=0.5, color='purple')\n",
    "    axes[2].plot(year_stats['year'], year_stats['high_tc_fraction'] * 100, \n",
    "                 linewidth=2, color='purple')\n",
    "    axes[2].set_xlabel('Publication Year', fontsize=11, fontweight='bold')\n",
    "    axes[2].set_ylabel('High-Tc Materials (%)', fontsize=11, fontweight='bold')\n",
    "    axes[2].set_title('Fraction of High-Tc Materials (>77K)', fontsize=13, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, '04d_temporal_trends.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved: 04d_temporal_trends.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "725a3360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.1] Quality tier analysis...\n",
      "  Quality tier statistics:\n",
      "                count  mean_tc  median_tc  std_tc  min_tc  max_tc\n",
      "quality_tier                                                     \n",
      "tier1_strict    14531    29.77       14.5   32.66    0.01   294.0\n",
      "tier2_standard   1314    30.95       13.3   34.54    0.06   287.0\n",
      "Saved: 05a_quality_tiers.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5.1] Quality tier analysis...\")\n",
    "\n",
    "if 'quality_tier' in df.columns:\n",
    "    tier_stats = df.groupby('quality_tier').agg({\n",
    "        'tc_kelvin': ['count', 'mean', 'median', 'std', 'min', 'max']\n",
    "    }).round(2)\n",
    "    tier_stats.columns = ['count', 'mean_tc', 'median_tc', 'std_tc', 'min_tc', 'max_tc']\n",
    "    tier_stats.to_csv(os.path.join(TABLES_DIR, 'quality_tier_stats.csv'))\n",
    "    \n",
    "    print(\"  Quality tier statistics:\")\n",
    "    print(tier_stats)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Pie chart of counts\n",
    "    tier_counts = df['quality_tier'].value_counts()\n",
    "    axes[0].pie(tier_counts.values, labels=tier_counts.index, autopct='%1.1f%%',\n",
    "                startangle=90, colors=plt.cm.Set3(range(len(tier_counts))))\n",
    "    axes[0].set_title('Distribution of Quality Tiers', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    # Bar chart of mean Tc\n",
    "    axes[1].bar(range(len(tier_stats)), tier_stats['mean_tc'], \n",
    "                yerr=tier_stats['std_tc'], capsize=5,\n",
    "                color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_xticks(range(len(tier_stats)))\n",
    "    axes[1].set_xticklabels(tier_stats.index, rotation=45, ha='right')\n",
    "    axes[1].set_ylabel('Mean Tc (K)', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Mean Tc by Quality Tier', fontsize=13, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, '05a_quality_tiers.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved: 05a_quality_tiers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9d4520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.2] Data quality flags summary...\n",
      "  Quality flags summary:\n",
      "                    flag  count  percentage\n",
      "      Oxygen Variability    447    2.821079\n",
      "       Duplicate Formula   2881   18.182392\n",
      "          High-Tc (>77K)   2346   14.805932\n",
      "   Multiple Measurements   2875   18.144525\n",
      "         Low Uncertainty  14696   92.748501\n",
      "Recent Discovery (>2000)   4693   29.618176\n",
      "Saved: 05b_quality_flags.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5.2] Data quality flags summary...\")\n",
    "\n",
    "quality_flags = {\n",
    "    'Oxygen Variability': 'has_oxygen_var',\n",
    "    'Duplicate Formula': 'is_duplicate_formula',\n",
    "    'High-Tc (>77K)': 'is_high_tc',\n",
    "    'Multiple Measurements': lambda: (df['n_measurements'] > 1).sum(),\n",
    "    'Low Uncertainty': lambda: (df['tc_std'] < 1).sum(),\n",
    "    'Recent Discovery (>2000)': lambda: (df['publication_year'] > 2000).sum()\n",
    "}\n",
    "\n",
    "flag_summary = []\n",
    "for flag_name, flag_col in quality_flags.items():\n",
    "    if callable(flag_col):\n",
    "        count = flag_col()\n",
    "    elif flag_col in df.columns:\n",
    "        count = df[flag_col].sum()\n",
    "    else:\n",
    "        count = 0\n",
    "    \n",
    "    pct = 100 * count / len(df)\n",
    "    flag_summary.append({\n",
    "        'flag': flag_name,\n",
    "        'count': count,\n",
    "        'percentage': pct\n",
    "    })\n",
    "\n",
    "flag_df = pd.DataFrame(flag_summary)\n",
    "flag_df.to_csv(os.path.join(TABLES_DIR, 'quality_flags_summary.csv'), index=False)\n",
    "\n",
    "print(\"  Quality flags summary:\")\n",
    "print(flag_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "colors = plt.cm.Set3(range(len(flag_df)))\n",
    "bars = ax.barh(range(len(flag_df)), flag_df['percentage'], color=colors, edgecolor='black')\n",
    "\n",
    "# Add count labels\n",
    "for i, (bar, row) in enumerate(zip(bars, flag_df.itertuples())):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{row.count:,}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "ax.set_yticks(range(len(flag_df)))\n",
    "ax.set_yticklabels(flag_df['flag'], fontsize=11)\n",
    "ax.set_xlabel('Percentage of Materials (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Data Quality Flags Distribution', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '05b_quality_flags.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: 05b_quality_flags.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41234508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.3] Measurement reliability analysis...\n",
      "  Measurement reliability:\n",
      "    Total materials: 15,845\n",
      "    With multiple measurements: 2,875\n",
      "    Percentage: 18.14\n",
      "    Mean measurements: 1.49\n",
      "    Max measurements: 151\n",
      "    Mean Tc std (multi-meas): 2.77\n",
      "    Materials with Tc std < 1K: 1726.00\n",
      "Saved: 05c_measurement_reliability.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5.3] Measurement reliability analysis...\")\n",
    "\n",
    "if 'n_measurements' in df.columns and 'tc_std' in df.columns:\n",
    "    # Materials with multiple measurements\n",
    "    multi_meas = df[df['n_measurements'] > 1]\n",
    "    \n",
    "    reliability_stats = {\n",
    "        'Total materials': len(df),\n",
    "        'With multiple measurements': len(multi_meas),\n",
    "        'Percentage': 100 * len(multi_meas) / len(df),\n",
    "        'Mean measurements': df['n_measurements'].mean(),\n",
    "        'Max measurements': df['n_measurements'].max(),\n",
    "        'Mean Tc std (multi-meas)': multi_meas['tc_std'].mean(),\n",
    "        'Materials with Tc std < 1K': (multi_meas['tc_std'] < 1).sum()\n",
    "    }\n",
    "    \n",
    "    print(\"  Measurement reliability:\")\n",
    "    for key, value in reliability_stats.items():\n",
    "        if 'Percentage' in key or 'Mean' in key or 'std' in key:\n",
    "            print(f\"    {key}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"    {key}: {value:,}\")\n",
    "    \n",
    "    # Plot: Tc std vs n_measurements\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(multi_meas['n_measurements'], multi_meas['tc_std'], \n",
    "                   alpha=0.3, s=30, edgecolors='k', linewidth=0.5)\n",
    "    axes[0].set_xlabel('Number of Measurements', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Tc Standard Deviation (K)', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Measurement Variability', fontsize=13, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution of Tc std\n",
    "    axes[1].hist(multi_meas['tc_std'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "    axes[1].axvline(1, color='red', linestyle='--', linewidth=2, label='1K threshold')\n",
    "    axes[1].set_xlabel('Tc Standard Deviation (K)', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Distribution of Measurement Uncertainty', fontsize=13, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, '05c_measurement_reliability.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved: 05c_measurement_reliability.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda097ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.4] Creating data quality badge system...\n",
      "  Quality score distribution:\n",
      "quality_score\n",
      "2     280\n",
      "3     165\n",
      "4    7631\n",
      "5    6098\n",
      "6    1102\n",
      "7     561\n",
      "8       8\n",
      "Name: count, dtype: int64\n",
      "Saved: quality_badge_system.csv\n",
      "Saved: 05d_quality_badges.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5.4] Creating data quality badge system...\")\n",
    "\n",
    "def assign_quality_badge(row):\n",
    "    \"\"\"Assign quality badge based on multiple criteria\"\"\"\n",
    "    score = 0\n",
    "    badges = []\n",
    "    \n",
    "    # Tier 1 data\n",
    "    if row.get('quality_tier') == 'tier1_strict':\n",
    "        score += 3\n",
    "        badges.append('Tier1')\n",
    "    elif row.get('quality_tier') == 'tier2_standard':\n",
    "        score += 2\n",
    "        badges.append('Tier2')\n",
    "    \n",
    "    # No oxygen variability\n",
    "    if not row.get('has_oxygen_var', True):\n",
    "        score += 1\n",
    "        badges.append('StableFormula')\n",
    "    \n",
    "    # Multiple measurements with low uncertainty\n",
    "    if row.get('n_measurements', 1) > 1 and row.get('tc_std', 999) < 2:\n",
    "        score += 2\n",
    "        badges.append('ReliableMeasurement')\n",
    "    \n",
    "    # High-Tc material\n",
    "    if row.get('is_high_tc', False):\n",
    "        score += 1\n",
    "        badges.append('HighTc')\n",
    "    \n",
    "    # Recent discovery\n",
    "    if row.get('publication_year', 0) > 2000:\n",
    "        score += 1\n",
    "        badges.append('Modern')\n",
    "    \n",
    "    return score, ', '.join(badges) if badges else 'None'\n",
    "\n",
    "# Apply badge system\n",
    "df['quality_score'], df['quality_badges'] = zip(*df.apply(assign_quality_badge, axis=1))\n",
    "\n",
    "# Badge distribution\n",
    "badge_dist = df['quality_score'].value_counts().sort_index()\n",
    "print(\"  Quality score distribution:\")\n",
    "print(badge_dist)\n",
    "\n",
    "# Save badge system\n",
    "badge_export = df[['data_number', 'chemical_formula', 'tc_kelvin', \n",
    "                   'quality_tier', 'quality_score', 'quality_badges']].copy()\n",
    "badge_export.to_csv(os.path.join(TABLES_DIR, 'quality_badge_system.csv'), index=False)\n",
    "print(\"Saved: quality_badge_system.csv\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Score distribution\n",
    "axes[0].bar(badge_dist.index, badge_dist.values, \n",
    "            color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Quality Score', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Materials', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Quality Score Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Mean Tc by quality score\n",
    "score_tc = df.groupby('quality_score')['tc_kelvin'].agg(['mean', 'std', 'count'])\n",
    "axes[1].bar(score_tc.index, score_tc['mean'], yerr=score_tc['std'], \n",
    "            capsize=5, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Quality Score', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Mean Tc (K)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Mean Tc by Quality Score', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '05d_quality_badges.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: 05d_quality_badges.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d44df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.3] Measurement reliability analysis...\n",
      "  Measurement reliability:\n",
      "    Total materials: 15,845\n",
      "    With multiple measurements: 2,875\n",
      "    Percentage: 18.14\n",
      "    Mean measurements: 1.49\n",
      "    Max measurements: 151\n",
      "    Mean Tc std (multi-meas): 2.77\n",
      "    Materials with Tc std < 1K: 1726.00\n",
      "Saved: 05c_measurement_reliability.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5.3] Measurement reliability analysis...\")\n",
    "\n",
    "if 'n_measurements' in df.columns and 'tc_std' in df.columns:\n",
    "    # Materials with multiple measurements\n",
    "    multi_meas = df[df['n_measurements'] > 1]\n",
    "    \n",
    "    reliability_stats = {\n",
    "        'Total materials': len(df),\n",
    "        'With multiple measurements': len(multi_meas),\n",
    "        'Percentage': 100 * len(multi_meas) / len(df),\n",
    "        'Mean measurements': df['n_measurements'].mean(),\n",
    "        'Max measurements': df['n_measurements'].max(),\n",
    "        'Mean Tc std (multi-meas)': multi_meas['tc_std'].mean(),\n",
    "        'Materials with Tc std < 1K': (multi_meas['tc_std'] < 1).sum()\n",
    "    }\n",
    "    \n",
    "    print(\"  Measurement reliability:\")\n",
    "    for key, value in reliability_stats.items():\n",
    "        if 'Percentage' in key or 'Mean' in key or 'std' in key:\n",
    "            print(f\"    {key}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"    {key}: {value:,}\")\n",
    "    \n",
    "    # Plot: Tc std vs n_measurements\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(multi_meas['n_measurements'], multi_meas['tc_std'], \n",
    "                   alpha=0.3, s=30, edgecolors='k', linewidth=0.5)\n",
    "    axes[0].set_xlabel('Number of Measurements', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Tc Standard Deviation (K)', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Measurement Variability', fontsize=13, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution of Tc std\n",
    "    axes[1].hist(multi_meas['tc_std'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "    axes[1].axvline(1, color='red', linestyle='--', linewidth=2, label='1K threshold')\n",
    "    axes[1].set_xlabel('Tc Standard Deviation (K)', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_title('Distribution of Measurement Uncertainty', fontsize=13, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, '05c_measurement_reliability.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved: 05c_measurement_reliability.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a25e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.4] Creating data quality badge system...\n",
      "Quality score distribution:\n",
      "quality_score\n",
      "2     280\n",
      "3     165\n",
      "4    7631\n",
      "5    6098\n",
      "6    1102\n",
      "7     561\n",
      "8       8\n",
      "Name: count, dtype: int64\n",
      "Saved: quality_badge_system.csv\n",
      "Saved: 05d_quality_badges.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5.4] Creating data quality badge system...\")\n",
    "\n",
    "def assign_quality_badge(row):\n",
    "    \"\"\"Assign quality badge based on multiple criteria\"\"\"\n",
    "    score = 0\n",
    "    badges = []\n",
    "    \n",
    "    # Tier 1 data\n",
    "    if row.get('quality_tier') == 'tier1_strict':\n",
    "        score += 3\n",
    "        badges.append('Tier1')\n",
    "    elif row.get('quality_tier') == 'tier2_standard':\n",
    "        score += 2\n",
    "        badges.append('Tier2')\n",
    "    \n",
    "    # No oxygen variability\n",
    "    if not row.get('has_oxygen_var', True):\n",
    "        score += 1\n",
    "        badges.append('StableFormula')\n",
    "    \n",
    "    # Multiple measurements with low uncertainty\n",
    "    if row.get('n_measurements', 1) > 1 and row.get('tc_std', 999) < 2:\n",
    "        score += 2\n",
    "        badges.append('ReliableMeasurement')\n",
    "    \n",
    "    # High-Tc material\n",
    "    if row.get('is_high_tc', False):\n",
    "        score += 1\n",
    "        badges.append('HighTc')\n",
    "    \n",
    "    # Recent discovery\n",
    "    if row.get('publication_year', 0) > 2000:\n",
    "        score += 1\n",
    "        badges.append('Modern')\n",
    "    \n",
    "    return score, ', '.join(badges) if badges else 'None'\n",
    "\n",
    "# Apply badge system\n",
    "df['quality_score'], df['quality_badges'] = zip(*df.apply(assign_quality_badge, axis=1))\n",
    "\n",
    "# Badge distribution\n",
    "badge_dist = df['quality_score'].value_counts().sort_index()\n",
    "print(\"Quality score distribution:\")\n",
    "print(badge_dist)\n",
    "\n",
    "# Save badge system\n",
    "badge_export = df[['data_number', 'chemical_formula', 'tc_kelvin', \n",
    "                   'quality_tier', 'quality_score', 'quality_badges']].copy()\n",
    "badge_export.to_csv(os.path.join(TABLES_DIR, 'quality_badge_system.csv'), index=False)\n",
    "print(\"Saved: quality_badge_system.csv\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Score distribution\n",
    "axes[0].bar(badge_dist.index, badge_dist.values, \n",
    "            color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Quality Score', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Materials', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Quality Score Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Mean Tc by quality score\n",
    "score_tc = df.groupby('quality_score')['tc_kelvin'].agg(['mean', 'std', 'count'])\n",
    "axes[1].bar(score_tc.index, score_tc['mean'], yerr=score_tc['std'], \n",
    "            capsize=5, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Quality Score', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Mean Tc (K)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Mean Tc by Quality Score', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '05d_quality_badges.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: 05d_quality_badges.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4778023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.9.13",
   "language": "python",
   "name": "python_3.9.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

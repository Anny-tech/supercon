# Deployment Guide

## Deploying to GitHub

### Step 1: Prepare Repository

```bash
# Initialize git (if not already done)
git init
git add .
git commit -m "Initial commit: Superconductor dashboard"

# Connect to GitHub
git remote add origin https://github.com/Anny-tech/supercon.git
git branch -M main
git push -u origin main
```

### Step 2: Handle Large Data Files

**Option A: Git LFS** (recommended for files < 2GB)

```bash
# Install Git LFS
git lfs install

# Track CSV files
git lfs track "data/*.csv"
git add .gitattributes
git commit -m "Add Git LFS tracking"
git push
```

**Option B: External Hosting**
- Upload data files to Google Drive, Dropbox, or Zenodo
- Update `setup_database.py` to download from URL
- Add download script:

```python
import requests

def download_data():
    """Download data files from external source"""
    urls = {
        'superconductors_with_features.csv': 'YOUR_URL_HERE',
        'tc_by_element.csv': 'YOUR_URL_HERE',
        'feature_importance.csv': 'YOUR_URL_HERE'
    }
    
    for filename, url in urls.items():
        if not os.path.exists(f'data/{filename}'):
            print(f"Downloading {filename}...")
            response = requests.get(url)
            with open(f'data/{filename}', 'wb') as f:
                f.write(response.content)
```

### Step 3: Create data/.gitkeep

```bash
mkdir -p data
touch data/.gitkeep
git add data/.gitkeep
git commit -m "Add data directory structure"
```

---

## Deploying to Cloud Platforms

### Option 1: Heroku (Free Tier)

**File: `Procfile`**
```
web: gunicorn app:server
release: python setup_database.py
```

**Steps:**
```bash
# Install Heroku CLI
heroku login

# Create app
heroku create supercon-dashboard

# Add PostgreSQL addon
heroku addons:create heroku-postgresql:mini

# Deploy
git push heroku main

# Open app
heroku open
```

### Option 2: Railway.app (Recommended)

1. Go to [Railway.app](https://railway.app)
2. Connect GitHub repository
3. Add PostgreSQL service
4. Set environment variables
5. Deploy automatically on push

**Environment Variables:**
```
POSTGRES_USER=postgres
POSTGRES_PASSWORD=<auto-generated>
POSTGRES_HOST=<auto-provided>
POSTGRES_PORT=5432
POSTGRES_DB=superconductors
```

### Option 3: Render.com

**File: `render.yaml`**
```yaml
services:
  - type: web
    name: supercon-dashboard
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: gunicorn app:server
    envVars:
      - key: POSTGRES_HOST
        fromDatabase:
          name: supercon-db
          property: host
      - key: POSTGRES_USER
        fromDatabase:
          name: supercon-db
          property: user

databases:
  - name: supercon-db
    databaseName: superconductors
    user: postgres
```

### Option 4: DigitalOcean App Platform

1. Create new app from GitHub repo
2. Add managed PostgreSQL database
3. Configure environment variables
4. Deploy

---

## Local Production Testing

```bash
# Build production image
docker-compose build

# Run with production settings
docker-compose up -d

# Check logs
docker-compose logs -f

# Test endpoint
curl http://localhost:8050
```

---

## Database Backup & Restore

### Backup

```bash
# Backup database
docker exec supercon_db pg_dump -U postgres superconductors > backup.sql

# Backup with timestamp
docker exec supercon_db pg_dump -U postgres superconductors > backup_$(date +%Y%m%d).sql
```

### Restore

```bash
# Restore from backup
docker exec -i supercon_db psql -U postgres superconductors < backup.sql
```

---

## Monitoring & Maintenance

### Health Checks

```bash
# Check container status
docker-compose ps

# Check database connection
docker exec supercon_db pg_isready -U postgres

# Check app logs
docker-compose logs app | tail -50
```

### Performance Tuning

**PostgreSQL Configuration** (`postgresql.conf`)
```conf
# For small datasets (~16k records)
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 128MB
```

**Gunicorn Workers**
```yaml
# In docker-compose.yml
command: gunicorn -b 0.0.0.0:8050 app:server --workers 4 --timeout 120
```

---

## Troubleshooting

### Issue: Database connection failed

```bash
# Check database is running
docker-compose ps db

# Check database logs
docker-compose logs db

# Restart database
docker-compose restart db
```

### Issue: Data files missing

```bash
# Check data directory
ls -lh data/

# Re-run database setup
docker-compose run db_init python setup_database.py
```

### Issue: Port already in use

```bash
# Find process using port 8050
lsof -i :8050

# Kill process
kill -9 <PID>

# Or change port in docker-compose.yml
ports:
  - "8051:8050"  # Use 8051 externally
```

---

## Security Considerations

### Production Settings

1. **Change default passwords**
```yaml
environment:
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}  # Use environment variable
```

2. **Use secrets management**
```bash
# Create .env file (not committed)
echo "POSTGRES_PASSWORD=secure_password_here" > .env
```

3. **Enable HTTPS** (via reverse proxy)
```nginx
# nginx.conf
server {
    listen 443 ssl;
    server_name supercon.yourdomain.com;
    
    location / {
        proxy_pass http://localhost:8050;
    }
}
```

---

## CI/CD Pipeline (GitHub Actions)

**File: `.github/workflows/deploy.yml`**
```yaml
name: Deploy Dashboard

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: docker-compose build
      
      - name: Run tests
        run: docker-compose run app pytest
      
      - name: Deploy to production
        run: |
          # Add deployment commands here
```

---

## Scaling Considerations

### For Larger Datasets (>100k records)

1. **Add caching** (Redis)
2. **Use connection pooling** (pgbouncer)
3. **Optimize queries** (materialized views)
4. **Add CDN** for static assets

---

## Cost Estimates

| Platform | Free Tier | Paid Tier |
|----------|-----------|-----------|
| Heroku | 550 hours/month | $7/month (Hobby) |
| Railway | 500 hours + $5 credit | $5/month |
| Render | 750 hours/month | $7/month |
| DigitalOcean | $200 credit (60 days) | $5/month |

**Recommendation**: Railway.app for ease of use and cost

---

Last updated: December 2025
